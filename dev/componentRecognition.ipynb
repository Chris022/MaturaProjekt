{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import layers, models\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import lib.utils as utils\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertImg(image, size=(32,32)):\n",
    "    image = cv2.resize(image, size, interpolation=cv2.INTER_AREA)\n",
    "    converted = np.zeros(shape=(size[0], size[1], 1))\n",
    "    for y in range(0, len(image)):\n",
    "        for x in range(0, len(image[y])):\n",
    "            converted[y][x][0] = image[y][x]\n",
    "\n",
    "    converted = converted/255\n",
    "    return converted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainImages / Images\n",
    "ratio = 0.7\n",
    "train_data = []\n",
    "test_data = []\n",
    "\n",
    "class_names = os.listdir('./../resources/trainData_new')\n",
    "print(class_names)\n",
    "\n",
    "for class_name in class_names:\n",
    "    data = os.listdir('./../resources/trainData_new/{class_name}'.format(class_name=class_name))\n",
    "    for i in range(0, len(data)):\n",
    "        image = convertImg(utils.loadImage(path='./../resources/trainData_new/{class_name}'.format(class_name=class_name), name=data[i], resize=(32,32)))\n",
    "        #image = convertImg(utils.loadImage(path='./trainData/{class_name}'.format(class_name=class_name), name=data[i], resize=(32,32)))\n",
    "\n",
    "        label = [0 for i in range(0,len(class_names))]# + 4)]\n",
    "        #if 'u' in data[i]: label[len(label)-4] = 1\n",
    "        #if 'd' in data[i]: label[len(label)-3] = 1\n",
    "        #if 'l' in data[i]: label[len(label)-2] = 1\n",
    "        #if 'r' in data[i]: label[len(label)-1] = 1\n",
    "        label[class_names.index(class_name)] = 1\n",
    "\n",
    "        if(i/len(data) < ratio):\n",
    "            train_data.append((image,label))\n",
    "        else:\n",
    "            test_data.append((image,label))\n",
    "\n",
    "#class_names += ['up', 'down', 'left', 'right']\n",
    "print(class_names)\n",
    "\n",
    "random.shuffle(train_data)\n",
    "random.shuffle(test_data)\n",
    "\n",
    "train_images = []\n",
    "train_labels = []\n",
    "test_images = []\n",
    "test_labels = []\n",
    "\n",
    "for data in train_data:\n",
    "    train_images.append(data[0])\n",
    "    train_labels.append(data[1])\n",
    "\n",
    "for data in test_data:\n",
    "    test_images.append(data[0])\n",
    "    test_labels.append(data[1])\n",
    "\n",
    "\n",
    "train_images = np.asarray(train_images)\n",
    "train_labels = np.asarray(train_labels)\n",
    "test_images = np.asarray(test_images)\n",
    "test_labels = np.asarray(test_labels)\n",
    "\n",
    "print(len(train_images))\n",
    "print(len(test_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "for i in range(6):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(train_images[i], cmap='gray')\n",
    "    # The CIFAR labels happen to be arrays, \n",
    "    # which is why you need the extra index\n",
    "    #plt.xlabel(class_names[train_labels[i][0]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu', input_shape=(32, 32, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(256, (3, 3), activation='relu'))\n",
    "model.add(layers.Conv2D(512, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(1024, (3, 3), activation='relu'))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "#model.add(layers.Dense(len(class_names)))\n",
    "model.add(layers.Dense(len(class_names), activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.compile(optimizer='adam',\n",
    "#              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "#              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "              metrics=[tf.keras.metrics.BinaryAccuracy()])\n",
    "              \n",
    "\n",
    "#history = model.fit(train_images, train_labels, epochs=10, \n",
    "#                    validation_data=(test_images, test_labels))\n",
    "\n",
    "history = model.fit(train_images, train_labels, epochs=20, \n",
    "                    validation_data=(test_images, test_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('./../resources/saved_model/my_model')\n",
    "\n",
    "model.save('./../resources/saved_model/my_model.h5')\n",
    "del model\n",
    "\n",
    "# returns a compiled model\n",
    "# identical to the previous one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#boxes = [[[45,118],[80,184]],[[250,115],[300,141]]]\n",
    "#image = utils.loadImage(\"../src/testImages\", \"1.png\")\n",
    "\n",
    "def classify(boxes, image):\n",
    "    \n",
    "    model = tf.keras.models.load_model('./../resources/saved_model/my_model')\n",
    "\n",
    "    components = []\n",
    "    for box in boxes:\n",
    "        component = image[box[0][1]:box[1][1], box[0][0]:box[1][0]]\n",
    "        components.append(convertImg(component).reshape(-1,32,32,1))\n",
    "\n",
    "    modelPredictions = model.predict(np.vstack(components))\n",
    "\n",
    "    predictions = []\n",
    "\n",
    "    for prediction in modelPredictions:\n",
    "        print(prediction)\n",
    "        predictions.append(class_names[np.argmax(predictions_single)])\n",
    "        #predictions.append([class_names[np.argmax(prediction[:-4])],class_names[-4:][np.argmax(prediction[-4:])]])\n",
    "\n",
    "        #predictions.append(class_names[np.argmax(prediction)])\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = tf.keras.models.load_model('./../resources/saved_model/my_model')\n",
    "\n",
    "model = load_model('./../resources/saved_model/my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['capacitor', 'ground', 'inductor', 'resistor', 'voltage']\n",
      "[1.3936667e-18 2.1133357e-16 1.0000000e+00 1.3062073e-23 5.6967515e-20]\n",
      "inductor\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x224c9910550>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Check its architecture\n",
    "#new_model.summary()\n",
    "\n",
    "#img = convertImg(utils.loadImage(path='./../resources/trainData', name='3.png', resize=(32,32)))\n",
    "\n",
    "img = test_images[0]\n",
    "#img = train_images[12]\n",
    "\n",
    "\n",
    "predictions_single = model.predict(img.reshape(-1,32,32,1))[0]\n",
    "print(class_names)\n",
    "print(predictions_single)\n",
    "print(class_names[np.argmax(predictions_single)])\n",
    "#print(class_names[np.where(predictions_single[:-4] == np.amax(predictions_single[:-4]))[0][0]])\n",
    "#print(class_names[np.where(predictions_single[-4:] == np.amax(predictions_single[-4:]))[0][0] + len(class_names) - 4])\n",
    "\n",
    "plt.imshow(img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "for i in range(6):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(test_images[i], cmap='gray')\n",
    "\n",
    "    predictions_single = model.predict(test_images[i].reshape(-1,32,32,1))[0]\n",
    "    # The CIFAR labels happen to be arrays, \n",
    "    # which is why you need the extra index\n",
    "    plt.xlabel(class_names[np.argmax(predictions_single)])\n",
    "    #plt.xlabel(class_names[np.where(predictions_single[:-4] == np.amax(predictions_single[:-4]))[0][0]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['val_binary_accuracy'], label='val_accuracy')\n",
    "plt.plot(history.history['binary_accuracy'], label = 'accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=1)\n",
    "#test_loss, test_acc = model.evaluate(train_images,  train_labels, verbose=1)\n",
    "print(test_labels)\n",
    "print(test_acc)\n",
    "print(test_loss)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6c255580c1376a53e8d62a65f4b290fc9e06ee65b5dbb546bacb4a0a6e644e58"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit (windows store)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
