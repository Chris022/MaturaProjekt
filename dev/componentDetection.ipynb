{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import layers, models\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import lib.utils as utils\n",
    "from lib.constants import S, B, C, INPUT_SIZE, CLASS_NAMES,CLASS_COLORS, LAMBDA_COORD, LAMBDA_NOOBJ\n",
    "import os\n",
    "import cv2\n",
    "import math\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.txt', '1.txt', '10.txt', '11.txt', '2.txt', '3.txt', '4.txt', '5.txt', '6.txt', '7.txt', '8.txt', '9.txt']\n"
     ]
    }
   ],
   "source": [
    "label_names = os.listdir('./../resources/labeled_data/labels')\n",
    "print(label_names)\n",
    "\n",
    "labels = []\n",
    "for label_name in label_names:\n",
    "    file = open(str('./../resources/labeled_data/labels/' + label_name), 'rb')\n",
    "    label = pickle.load(file)\n",
    "    file.close()\n",
    "    labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.png', '1.png', '10.png', '11.png', '2.png', '3.png', '4.png', '5.png', '6.png', '7.png', '8.png', '9.png']\n"
     ]
    }
   ],
   "source": [
    "image_names = os.listdir('./../resources/labeled_data/images')\n",
    "print(image_names)\n",
    "\n",
    "images = []\n",
    "for image_name in image_names:\n",
    "    image = utils.loadImage(path='./../resources/labeled_data/images', name=image_name, resize=(INPUT_SIZE,INPUT_SIZE),color=False)\n",
    "    images.append(image)\n",
    "\n",
    "if len(images) != len(labels):\n",
    "    sys.exit('#labels != #images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pc  Bx  By  Bw  Bh     C1 C2\n",
    "#0   0   0   0   0      0  0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#only works for B=1\n",
    "def get_output_tensor(label):\n",
    "    shape = (S,S,5*B+C)\n",
    "    out = np.zeros(shape)\n",
    "    cell_size = (int)(INPUT_SIZE/S)\n",
    "\n",
    "\n",
    "    for box in label:\n",
    "        \n",
    "        x_cell = math.floor(box['b_x']/cell_size)\n",
    "        y_cell = math.floor(box['b_y']/cell_size)\n",
    "\n",
    "        if not np.array_equal(out[x_cell][y_cell], np.zeros(5*B+C)):\n",
    "            sys.exit('More then one bounding box in cell')\n",
    "\n",
    "        y = np.zeros(5*B+C)\n",
    "        y[CLASS_NAMES.index(box['c'])-C] = 1\n",
    "\n",
    "        y[0] = 1\n",
    "        y[1] = (box['b_x'] - cell_size*x_cell) / cell_size\n",
    "        y[2] = (box['b_y'] - cell_size*y_cell) / cell_size\n",
    "        y[3] = box['b_w'] / INPUT_SIZE\n",
    "        y[4] = box['b_h'] / INPUT_SIZE\n",
    "\n",
    "        out[x_cell][y_cell] = y\n",
    "    return out.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 448, 448)\n",
      "(12, 490)\n"
     ]
    }
   ],
   "source": [
    "train_images = []\n",
    "train_labels = []\n",
    "\n",
    "for i in range(0, len(images)):\n",
    "    train_images.append(images[i]/255)\n",
    "    train_labels.append(get_output_tensor(labels[i]))\n",
    "\n",
    "train_images = np.asarray(train_images)\n",
    "train_labels = np.asarray(train_labels)\n",
    "\n",
    "print(train_images.shape)\n",
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leaky_reLu(x):\n",
    "    return tf.keras.activations.relu(x, alpha=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createModel():    \n",
    "    model = models.Sequential()\n",
    "\n",
    "    model.add(layers.Conv2D(filters=64, kernel_size=(7, 7), strides=2, padding='same', activation=leaky_reLu, input_shape=(INPUT_SIZE, INPUT_SIZE, 1)))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2), strides=2))\n",
    "\n",
    "    model.add(layers.Conv2D(filters=192, kernel_size=(3, 3), padding='same', activation=leaky_reLu))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(layers.Conv2D(filters=128, kernel_size=(1, 1), padding='same', activation=leaky_reLu))\n",
    "    model.add(layers.Conv2D(filters=256, kernel_size=(3, 3), padding='same', activation=leaky_reLu))\n",
    "    model.add(layers.Conv2D(filters=128, kernel_size=(1, 1), padding='same', activation=leaky_reLu)) #256\n",
    "    model.add(layers.Conv2D(filters=512, kernel_size=(3, 3), padding='same', activation=leaky_reLu))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    for i in range(0,4):\n",
    "        model.add(layers.Conv2D(filters=256, kernel_size=(1, 1), padding='same', activation=leaky_reLu))\n",
    "        model.add(layers.Conv2D(filters=512, kernel_size=(3, 3), padding='same', activation=leaky_reLu))\n",
    "    model.add(layers.Conv2D(filters=512, kernel_size=(1, 1), padding='same', activation=leaky_reLu))\n",
    "    model.add(layers.Conv2D(filters=1024, kernel_size=(3, 3), padding='same', activation=leaky_reLu))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    for i in range(0,2):\n",
    "        model.add(layers.Conv2D(filters=512, kernel_size=(1, 1), padding='same', activation=leaky_reLu))\n",
    "        model.add(layers.Conv2D(filters=1024, kernel_size=(3, 3), padding='same', activation=leaky_reLu))\n",
    "    model.add(layers.Conv2D(filters=1024, kernel_size=(3, 3), padding='same', activation=leaky_reLu))\n",
    "    model.add(layers.Conv2D(filters=1024, kernel_size=(3, 3), strides=2, padding='same', activation=leaky_reLu))\n",
    "\n",
    "    model.add(layers.Conv2D(filters=1024, kernel_size=(3, 3), padding='same', activation=leaky_reLu))\n",
    "    model.add(layers.Conv2D(filters=1024, kernel_size=(3, 3), padding='same', activation=leaky_reLu))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    " \n",
    "    model.add(layers.Dense(4096, activation=leaky_reLu))\n",
    "    model.add(layers.Dense(S*S*(5*B+C)))\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(y_true, y_pred):\n",
    "\n",
    "  print(y_true)\n",
    "  print('--------------------------------------')\n",
    "  print(y_pred)\n",
    "\n",
    "  y_true = tf.reshape(y_true, (-1, S, S, 5*B+C))\n",
    "  y_pred = tf.reshape(y_pred, (-1, S, S, 5*B+C))\n",
    "\n",
    "  #print(y_true)\n",
    "  #print(y_pred)\n",
    "\n",
    "  #loss = tf.square(y_true - y_pred)\n",
    "  # ignore elements where BOTH y_true & y_pred < 0.1\n",
    "  #mask = tf.cast(tf.logical_or(y_true < 0, 1 >= 0.1) ,tf.float32)\n",
    "  #loss *= mask\n",
    "\n",
    "\n",
    "  #exists_box = tf.reshape(y_true[...,0:1], (-1,S*S))\n",
    "\n",
    "  exists_box = y_true[...,0:1]\n",
    "\n",
    "\n",
    "  y_pred_obj = tf.multiply(y_pred, exists_box)\n",
    "\n",
    "  y_pred_no_obj = tf.multiply(y_pred, tf.subtract(1, exists_box))\n",
    "  y_pred_no_obj = tf.add(y_pred_no_obj, tf.multiply(tf.cast(tf.fill(((1, S, S, 5*B+C)),1), 'float32') ,exists_box))\n",
    "\n",
    "  #box loss\n",
    "  box_loss1 = tf.math.reduce_sum(tf.math.squared_difference(y_true[...,1:3], y_pred_obj[...,1:3]))\n",
    "  box_loss2 = tf.math.reduce_sum(tf.math.squared_difference(tf.math.sqrt(tf.math.abs(y_true[...,3:5])), tf.math.sqrt(tf.math.abs(y_pred_obj[...,3:5]))))\n",
    "\n",
    "  box_loss = tf.math.add(box_loss1, box_loss2)\n",
    "\n",
    "  #print(box_loss)\n",
    "\n",
    "  #object loss\n",
    "  object_loss = tf.math.reduce_sum(tf.math.squared_difference(y_true[...,0:1], y_pred_obj[...,0:1]))\n",
    "\n",
    "  #print(object_loss)\n",
    "\n",
    "  #no object loss\n",
    "  no_object_loss = tf.math.reduce_sum(tf.math.squared_difference(y_true[...,0:1], y_pred_no_obj[...,0:1]))\n",
    "\n",
    "  #print(no_object_loss)\n",
    "\n",
    "  #class loss\n",
    "  class_loss = tf.math.reduce_sum(tf.math.squared_difference(y_true[...,5:10], y_pred_obj[...,5:10]))\n",
    "\n",
    "  #print(class_loss)\n",
    "\n",
    "  loss = tf.math.add_n([tf.math.multiply(LAMBDA_COORD, box_loss), tf.math.multiply(LAMBDA_NOOBJ, no_object_loss), object_loss, class_loss])\n",
    "\n",
    "\n",
    "  return loss#tf.reduce_sum(loss)# / tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_48 (Conv2D)           (None, 224, 224, 64)      3200      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_49 (Conv2D)           (None, 112, 112, 192)     110784    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 56, 56, 192)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_50 (Conv2D)           (None, 56, 56, 128)       24704     \n",
      "_________________________________________________________________\n",
      "conv2d_51 (Conv2D)           (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "conv2d_52 (Conv2D)           (None, 56, 56, 128)       32896     \n",
      "_________________________________________________________________\n",
      "conv2d_53 (Conv2D)           (None, 56, 56, 512)       590336    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 28, 28, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_54 (Conv2D)           (None, 28, 28, 256)       131328    \n",
      "_________________________________________________________________\n",
      "conv2d_55 (Conv2D)           (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_56 (Conv2D)           (None, 28, 28, 256)       131328    \n",
      "_________________________________________________________________\n",
      "conv2d_57 (Conv2D)           (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_58 (Conv2D)           (None, 28, 28, 256)       131328    \n",
      "_________________________________________________________________\n",
      "conv2d_59 (Conv2D)           (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_60 (Conv2D)           (None, 28, 28, 256)       131328    \n",
      "_________________________________________________________________\n",
      "conv2d_61 (Conv2D)           (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_62 (Conv2D)           (None, 28, 28, 512)       262656    \n",
      "_________________________________________________________________\n",
      "conv2d_63 (Conv2D)           (None, 28, 28, 1024)      4719616   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 14, 14, 1024)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_64 (Conv2D)           (None, 14, 14, 512)       524800    \n",
      "_________________________________________________________________\n",
      "conv2d_65 (Conv2D)           (None, 14, 14, 1024)      4719616   \n",
      "_________________________________________________________________\n",
      "conv2d_66 (Conv2D)           (None, 14, 14, 512)       524800    \n",
      "_________________________________________________________________\n",
      "conv2d_67 (Conv2D)           (None, 14, 14, 1024)      4719616   \n",
      "_________________________________________________________________\n",
      "conv2d_68 (Conv2D)           (None, 14, 14, 1024)      9438208   \n",
      "_________________________________________________________________\n",
      "conv2d_69 (Conv2D)           (None, 7, 7, 1024)        9438208   \n",
      "_________________________________________________________________\n",
      "conv2d_70 (Conv2D)           (None, 7, 7, 1024)        9438208   \n",
      "_________________________________________________________________\n",
      "conv2d_71 (Conv2D)           (None, 7, 7, 1024)        9438208   \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 50176)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 4096)              205524992 \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 490)               2007530   \n",
      "=================================================================\n",
      "Total params: 267,059,498\n",
      "Trainable params: 267,059,498\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#model = tf.keras.models.load_model('./../resources/saved_model/my_model', compile=False)\n",
    "\n",
    "model = createModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "              #loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              loss=loss,\n",
    "              run_eagerly=True,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "train_labels = tf.convert_to_tensor([train_labels[0]])\n",
    "\n",
    "#print(train_labels)\n",
    "train_images = tf.expand_dims([train_images[0]], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         1.         0.75       0.8984375  0.12946428\n",
      "  0.3236607  0.         0.         0.         1.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         1.         0.328125\n",
      "  0.15625    0.12723215 0.07254464 0.         1.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         1.         0.7109375\n",
      "  0.546875   0.13616072 0.12611607 1.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  1.         0.4609375  0.09375    0.1015625  0.0546875  0.\n",
      "  1.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  1.         0.15625    0.7421875  0.10714286 0.24441965 0.\n",
      "  0.         1.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  1.         0.171875   0.078125   0.1328125  0.21428572 0.\n",
      "  0.         0.         0.         1.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]], shape=(1, 490), dtype=float32)\n",
      "--------------------------------------\n",
      "tf.Tensor(\n",
      "[[ 1.8962194e-06  1.4861202e-05  2.0706493e-06 -4.6154823e-06\n",
      "   3.6308195e-06  4.6397163e-06 -9.7121683e-06  3.2432172e-07\n",
      "   3.1178756e-06  5.7072334e-06 -1.1710025e-05 -6.2501526e-06\n",
      "   3.9665711e-06  1.6034305e-06  1.3135903e-05  3.1740626e-07\n",
      "  -4.4582562e-06 -8.0069240e-06  1.1980948e-05 -7.5288781e-06\n",
      "  -8.4498415e-06  7.8944659e-06 -1.1883352e-05  7.6493707e-06\n",
      "   4.6040345e-06 -1.4040414e-05  2.4305032e-06  7.1084537e-07\n",
      "  -4.4485850e-07 -1.3357324e-05 -7.3047922e-06  3.6289571e-06\n",
      "   1.2656717e-06 -1.1491583e-05  1.3255054e-06 -1.8667124e-05\n",
      "  -7.2733445e-07 -6.0888406e-06  9.3258413e-06 -5.5594010e-06\n",
      "   8.6214259e-06  1.5660331e-05  2.3154809e-07 -4.1276303e-06\n",
      "   1.1044740e-05 -5.4062302e-06 -6.6193361e-06  6.4457254e-08\n",
      "  -6.1812784e-07  4.4034905e-06  3.6598171e-06 -1.0985967e-05\n",
      "  -1.2996925e-05 -1.0487711e-05  1.1997967e-05 -8.4658304e-06\n",
      "  -8.1703965e-06 -8.3206469e-06 -1.0910961e-06 -4.0082809e-06\n",
      "  -1.1926023e-05 -3.9858978e-06 -2.2624588e-06 -1.5433977e-07\n",
      "   1.8581957e-06  2.7705232e-07 -5.4804595e-06 -2.3151856e-06\n",
      "   3.9337037e-06 -2.0740117e-08 -3.3005470e-06  5.9415470e-06\n",
      "   3.3546112e-06  1.7783711e-06 -1.2873118e-05 -7.8489393e-06\n",
      "   4.5694646e-06 -9.1216370e-06 -1.2259026e-05  4.4586636e-06\n",
      "   3.9749634e-06 -1.1363650e-05  8.0080699e-06  1.1866885e-06\n",
      "   7.3691926e-06  3.9291211e-07 -2.3089819e-07 -1.3776985e-06\n",
      "  -1.1081793e-05 -6.3737821e-06 -5.6508720e-06  5.5987771e-06\n",
      "  -5.6349518e-07  1.5530743e-05  4.2473002e-06 -5.1556708e-07\n",
      "   1.7868929e-06  5.3715889e-06  1.0708332e-05  1.2860926e-06\n",
      "  -2.3553944e-06  3.4953564e-06  6.1755804e-07  3.5542203e-06\n",
      "  -2.6892790e-06  6.4568976e-06 -5.9511258e-06 -5.5712962e-07\n",
      "  -2.9445317e-07 -8.0181117e-06  4.1287722e-06 -2.3380239e-06\n",
      "  -7.9748979e-06  8.7976177e-06 -9.3657518e-06  1.8093835e-06\n",
      "   6.9959373e-07 -4.6686055e-06 -9.0290041e-06 -8.7191693e-06\n",
      "   8.8440102e-06  6.1238038e-06  4.4471058e-06 -5.4946950e-06\n",
      "  -7.0852984e-06  5.0264639e-06  2.7502611e-07  4.0741288e-06\n",
      "  -6.4677106e-06  5.4070447e-06  1.3318748e-06 -5.1116840e-06\n",
      "   7.3747760e-06 -6.5231266e-06 -5.0403008e-07 -7.5065786e-06\n",
      "  -4.1730805e-06 -1.0475800e-05  6.5025579e-06 -1.2174809e-05\n",
      "  -1.9099166e-06 -1.3071318e-05  1.2401583e-05 -2.8175953e-06\n",
      "  -1.7355007e-06  6.5437625e-06  9.0497842e-06 -1.8460244e-06\n",
      "  -8.8257329e-06 -1.4957263e-05  7.5123044e-06 -6.9855474e-07\n",
      "  -1.4964603e-05 -1.5354544e-07 -8.2068318e-06 -9.7233642e-06\n",
      "  -2.9551347e-06 -5.9525623e-06 -1.3403185e-05 -1.2395359e-06\n",
      "  -4.2258657e-06  6.0044058e-06 -4.3610667e-06 -6.4198666e-06\n",
      "   1.7416236e-06  1.6965343e-05  2.1682961e-06 -2.7054748e-06\n",
      "  -2.1454966e-06  4.9004757e-06  2.4973770e-06 -3.4643645e-06\n",
      "   1.4732143e-06  1.6410104e-05  2.4038363e-06  7.2592848e-06\n",
      "  -4.7563140e-06 -1.8283876e-07  7.2616526e-06 -4.8544725e-06\n",
      "   5.2898486e-06 -1.1090408e-06  3.7364277e-06 -7.3299934e-06\n",
      "  -6.3602465e-07  2.4073336e-07 -7.3597425e-06 -9.1125312e-06\n",
      "  -3.3881493e-06 -3.2772136e-06  1.3491170e-05  6.3616735e-06\n",
      "  -5.0240806e-06  1.9271522e-06 -2.3153223e-06 -4.9041855e-06\n",
      "   6.6911803e-06 -6.9772750e-06 -1.0053267e-05  2.2883178e-06\n",
      "   9.6136764e-06 -5.8316973e-06  5.5406517e-06  5.9167401e-06\n",
      "   1.2873068e-05 -3.3516862e-06 -2.1564128e-06  2.8657882e-06\n",
      "   2.7655856e-06 -6.1312044e-06  3.9401184e-06 -2.1136921e-06\n",
      "   3.0278579e-06  1.4183446e-05 -2.2147597e-06  5.5771629e-06\n",
      "  -4.0572932e-06  8.1769876e-06  1.6051090e-06  5.3466374e-06\n",
      "  -5.4757049e-07  3.9491483e-06  6.0134380e-06  5.2328562e-07\n",
      "  -4.4234384e-06 -1.0157016e-06 -6.1057466e-07  6.1462438e-06\n",
      "  -2.9654966e-06  3.2992864e-06 -8.0819727e-06 -5.9269387e-06\n",
      "   5.3117678e-06  2.9750433e-06  4.5306483e-06  6.0088732e-06\n",
      "  -7.9343572e-06 -4.1603039e-06  1.0415200e-05  1.9278521e-06\n",
      "   2.7524657e-06  3.6009528e-06  7.2451539e-06 -6.3805180e-07\n",
      "  -7.9032980e-06 -6.8406894e-07  5.6169029e-06 -6.7325900e-06\n",
      "   2.9706434e-06  8.1373037e-06 -5.6493759e-06 -3.1250897e-06\n",
      "  -1.0858075e-05 -7.4346376e-06 -1.1429208e-06 -6.6417283e-06\n",
      "   1.3095686e-06  6.5542467e-06  3.3276374e-06 -8.8870019e-07\n",
      "  -1.0793445e-05  2.9264716e-06 -3.0178858e-06  4.0796053e-06\n",
      "  -4.5799579e-06  2.4847818e-06  9.0314788e-06 -4.0619707e-06\n",
      "   7.4077570e-06  4.1486310e-06 -5.8155410e-06  2.6670432e-06\n",
      "  -1.3116872e-06  6.7391102e-06 -1.0383984e-05  5.9168650e-07\n",
      "   1.4847177e-07  3.9145848e-06  1.8558443e-06  2.1100766e-06\n",
      "  -8.7734916e-06  8.3862342e-06 -6.0783027e-06 -9.2116497e-06\n",
      "  -8.6358050e-06 -5.6349663e-06  1.2556123e-05 -1.3693143e-06\n",
      "  -3.9506726e-06 -1.9631284e-06  3.1417617e-06  9.5795476e-06\n",
      "  -2.8086044e-06  1.5867763e-05  2.5007505e-06 -2.2409570e-06\n",
      "  -3.8530243e-06 -1.2824179e-06  1.5648038e-05  2.6847183e-06\n",
      "   1.8994842e-05  1.1517081e-06  1.1022559e-05 -9.0613512e-06\n",
      "  -7.7454956e-07  1.3936918e-05  8.5794691e-06  2.0865359e-06\n",
      "  -9.6157401e-06 -5.5032979e-06  2.9856542e-06  2.4863652e-08\n",
      "  -9.2944229e-06 -1.4068257e-06  2.6457810e-06  5.7242614e-06\n",
      "  -6.8696258e-06 -5.4750885e-06  8.3993464e-06  3.9653241e-06\n",
      "  -4.5645325e-07 -6.1496653e-06  5.1950242e-06  1.4981575e-05\n",
      "  -2.9083744e-06  5.3750941e-06 -3.6570268e-06  1.5121662e-06\n",
      "   3.4335568e-07  3.6081462e-07 -1.1884198e-05 -1.3898914e-05\n",
      "   6.3572506e-06  2.5416421e-07 -4.6948207e-06 -2.9716464e-06\n",
      "   3.7030691e-06  4.3582854e-06 -1.9984561e-06 -1.2691351e-05\n",
      "   6.6957350e-06  3.5424159e-06 -8.4010926e-06  7.0575688e-06\n",
      "  -2.4554656e-06  1.5048646e-06 -9.3611097e-06 -3.1119466e-06\n",
      "  -4.8113293e-06  2.3631574e-06 -1.2135412e-05  1.3008403e-06\n",
      "  -3.2123567e-06  6.6780999e-06  7.6920896e-06 -2.3851303e-06\n",
      "   9.1135944e-06 -1.1434024e-06 -8.2466113e-07 -8.0992149e-06\n",
      "   6.2973127e-06 -3.6356298e-06 -1.5735749e-06  2.6791199e-06\n",
      "  -3.2303237e-06  5.7641915e-07 -3.6418855e-06  1.9371691e-06\n",
      "   1.1873648e-05  4.3260015e-06  1.7362638e-06  7.1604159e-06\n",
      "   8.4200610e-06 -2.3324799e-06  2.8398091e-07  4.1410635e-06\n",
      "  -4.4193266e-06  1.4405350e-06  8.9227742e-06 -1.3089008e-06\n",
      "  -2.6368878e-06  7.3240199e-06 -5.5462438e-06  1.0473202e-06\n",
      "   7.4358122e-06 -1.0009293e-05 -2.1359506e-06  1.2309396e-06\n",
      "  -3.2944160e-06 -4.6230934e-06  9.2860219e-06  3.6969886e-06\n",
      "   3.1441175e-07  3.5135504e-06 -7.4799345e-07  3.5738985e-06\n",
      "   4.8727820e-06 -1.0873550e-06 -2.1032120e-06  7.3303054e-06\n",
      "  -2.6282892e-06  8.8964034e-06 -2.0226241e-06  5.4922930e-06\n",
      "  -1.9297199e-06  2.8857246e-06 -6.8511381e-06 -1.4732537e-06\n",
      "   1.6132483e-06  1.3358487e-05 -6.2731838e-06  5.5187784e-06\n",
      "  -6.9623266e-06 -7.6649785e-06 -2.6191531e-06 -2.4611268e-06\n",
      "   1.4896699e-07 -1.1664929e-05 -9.2043405e-07  6.5808481e-06\n",
      "   2.7385956e-06  2.1114938e-06 -6.5086706e-06 -5.0044991e-06\n",
      "  -5.2382245e-07  7.8472436e-07  3.0435010e-06  2.1095238e-06\n",
      "  -6.2485282e-07  1.2563025e-06 -2.5560526e-06  1.2332459e-05\n",
      "   5.9067988e-06 -7.5223506e-06  1.3667428e-06 -4.4502358e-06\n",
      "  -3.0029462e-06 -7.5110224e-06  4.1880421e-06 -8.4170715e-06\n",
      "  -1.4610432e-06 -8.3635205e-06 -2.6528942e-06  7.4204827e-06\n",
      "   4.7593480e-06  1.0461785e-05 -1.0612669e-05 -6.3694292e-06\n",
      "  -1.0131770e-05 -5.0134231e-06  9.9652443e-06  3.0760559e-06\n",
      "   1.4710434e-06 -6.1298406e-06 -1.5758869e-05  1.2768824e-05\n",
      "  -6.0702209e-06  5.3754234e-06  4.5889433e-06 -8.8068591e-06\n",
      "   2.6816201e-06 -5.6107783e-06  2.6579173e-06  1.8960385e-06\n",
      "   4.1989856e-06  4.9062496e-06 -4.9769592e-06  8.0490299e-06\n",
      "   2.3976816e-07  1.3740417e-05 -9.3109099e-07 -1.5087569e-05\n",
      "  -1.1256769e-05 -1.2539617e-05  2.1556878e-07  3.5342200e-06\n",
      "  -7.7861278e-06  2.6827183e-06  5.9639542e-06 -9.5887017e-06\n",
      "   4.7057556e-06  9.7514203e-07 -1.0613372e-05  1.8890939e-06\n",
      "   4.7210769e-06 -5.8209062e-06 -3.8149324e-06  1.2350932e-05\n",
      "   1.2522229e-05 -1.1958070e-05]], shape=(1, 490), dtype=float32)\n",
      "1/1 [==============================] - 16s 16s/step - loss: 36.4382 - accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_images, train_labels, batch_size=1, epochs=1, use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./../resources/saved_model/my_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = tf.keras.models.load_model('./../resources/saved_model/my_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "#plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "#test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "test_loss, test_acc = model.evaluate(train_images,  train_labels, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.asarray(train_images[0]).reshape(1, INPUT_SIZE, INPUT_SIZE, 1)\n",
    "\n",
    "#img = tf.expand_dims(train_images[3], axis=0)\n",
    "\n",
    "\n",
    "img = utils.loadImage('./../resources/test_images/', 'hand_test_2.png', resize=(INPUT_SIZE,INPUT_SIZE), color=False)\n",
    "img = img/255\n",
    "img = img.reshape(1, INPUT_SIZE, INPUT_SIZE, 1)\n",
    "\n",
    "prediction = model.predict(img).reshape((S,S,(5*B)+C))\n",
    "\n",
    "color_img = np.asarray(img[0])\n",
    "color_img = color_img.reshape(INPUT_SIZE,INPUT_SIZE)\n",
    "color_img = np.float32(color_img)\n",
    "\n",
    "\n",
    "color_img = cv2.cvtColor(color_img, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "\n",
    "for x in range(0, S):\n",
    "    for y in range(0, INPUT_SIZE):\n",
    "        color_img[y][x*(int)(INPUT_SIZE/S)] = (0,0,0)\n",
    "\n",
    "\n",
    "for y in range(0, S):\n",
    "    for x in range(0, INPUT_SIZE):\n",
    "        color_img[y*(int)(INPUT_SIZE/S)][x] = (0,0,0)\n",
    "\n",
    "size = INPUT_SIZE / S\n",
    "\n",
    "for i in range(0,7):\n",
    "    for j in range(0,7):\n",
    "        if prediction[i][j][0] >= 0.5:\n",
    "            color = CLASS_COLORS[np.argmax(prediction[i][j][-C:])]\n",
    "            class_name = CLASS_NAMES[np.argmax(prediction[i][j][-C:])]\n",
    "\n",
    "            center_x = (int)(prediction[i][j][1]*size + i*size)\n",
    "            center_y = (int)(prediction[i][j][2]*size + j*size)\n",
    "            width = prediction[i][j][3] * INPUT_SIZE\n",
    "            height = prediction[i][j][4] * INPUT_SIZE\n",
    "            #cv2.circle(color_img, ((int)(center_x),(int)(center_y)),5,color,-1)\n",
    "            #cv2.putText(color_img, class_name, (center_x, center_y), cv2.FONT_HERSHEY_SIMPLEX, 1, color, thickness=3)\n",
    "            cv2.rectangle(color_img, ((int)(center_x-width/2), (int)(center_y-height/2)), ((int)(center_x+width/2), (int)(center_y+height/2)), color, thickness=(int)(5*prediction[i][j][0]))\n",
    "\n",
    "\n",
    "plt.imshow(color_img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = tf.constant([[[1,2,3,4,5,6],[1,2,3,4,5,6]],[[1,2,3,4,5,6],[1,2,3,4,5,6]]])\n",
    "\n",
    "#print(t1)\n",
    "\n",
    "#print(t3)\n",
    "t_pred = tf.constant([1,1.5,0.5,0.7,0.7,1,1,0,0,0,  0,0,0,0,0,0,0,0,0,0, 1,0.3,0.4,0.8,0.8,1,0,1,0,0,   0,0,0,0,0,0,0,0,0,0, ])\n",
    "t_pred = tf.reshape(t_pred, (2,2,10))\n",
    "\n",
    "print(t_pred)\n",
    "print(t_pred[...,0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = tf.constant([[[1,2,3,4,5,6],[1,2,3,4,5,6]],[[1,2,3,4,5,6],[1,2,3,4,5,6]]])\n",
    "t3 = tf.constant([1,1,1,1])\n",
    "t3 = tf.cast(t3, 'float32')\n",
    "#print(t3)\n",
    "\n",
    "\n",
    "t_true = tf.constant([1,0.5,0.5,0.7,0.7,0,1,0,0,0,  0,0,0,0,0,0,0,0,0,0, 1,0.3,0.4,0.8,0.8,1,0,0,0,0,   0,0,0,0,0,0,0,0,0,0, ])\n",
    "#t_pred = tf.constant([1,1.5,0.5,0.7,0.7,1,1,0,0,0,  1,0,0,0,0,0,1,0,0,0, 1,0.3,0.4,0.8,0.8,1,0,0,0,0,   1,0,0,0,0,1,0,0,0,0, ])\n",
    "\n",
    "t_pred = tf.constant([1,1.5,0.5,0.7,0.7,1,1,0,0,0,  0,0,0,0,0,0,0,0,0,0, 1,0.3,0.4,0.8,0.8,1,0,1,0,0,   0,0,0,0,0,0,0,0,0,0, ])\n",
    "\n",
    "\n",
    "\n",
    "x = custom_loss(t_true, t_pred)\n",
    "\n",
    "print(x)\n",
    "\n",
    "t_true = tf.reshape(t_true, (2,2,10))\n",
    "t_pred = tf.reshape(t_pred, (2,2,10))\n",
    "\n",
    "\n",
    "exists_box = t_true[...,0:1]\n",
    "\n",
    "#print(tf.reshape(exists_box, 4))\n",
    "#\n",
    "#print(t_pred)\n",
    "#print(exists_box)\n",
    "#\n",
    "#test = tf.multiply(t_pred, exists_box)\n",
    "#\n",
    "#print(test)\n",
    "\n",
    "\n",
    "\n",
    "#t_pred = tf.map_fn(lambda x: 2*x, t_pred)\n",
    "\n",
    "#t_pred = tf.math.multiply(t_pred, tf.constant())\n",
    "\n",
    "#print(t_true[...,1:3])\n",
    "#\n",
    "#t_l = tf.math.squared_difference(t_true, t_pred)\n",
    "#\n",
    "#print(t_l)\n",
    "#\n",
    "#t_l = tf.math.reduce_sum(t_l)\n",
    "\n",
    "#print(t_true)\n",
    "#\n",
    "#print(t_pred)\n",
    "\n",
    "#print(t_l)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6c255580c1376a53e8d62a65f4b290fc9e06ee65b5dbb546bacb4a0a6e644e58"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit (windows store)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
